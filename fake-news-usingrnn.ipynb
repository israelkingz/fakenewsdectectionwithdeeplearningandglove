{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:22.967986Z",
     "iopub.status.busy": "2022-03-08T08:21:22.9675Z",
     "iopub.status.idle": "2022-03-08T08:21:22.985821Z",
     "shell.execute_reply": "2022-03-08T08:21:22.985105Z",
     "shell.execute_reply.started": "2022-03-08T08:21:22.967891Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:23.793843Z",
     "iopub.status.busy": "2022-03-08T08:21:23.793404Z",
     "iopub.status.idle": "2022-03-08T08:21:25.17574Z",
     "shell.execute_reply": "2022-03-08T08:21:25.174804Z",
     "shell.execute_reply.started": "2022-03-08T08:21:23.793814Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_news = pd.read_csv('/kaggle/input/dataminingproject2/Fake.csv')\n",
    "true_news = pd.read_csv('/kaggle/input/dataminingproject2/True.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:25.177455Z",
     "iopub.status.busy": "2022-03-08T08:21:25.177189Z",
     "iopub.status.idle": "2022-03-08T08:21:25.222611Z",
     "shell.execute_reply": "2022-03-08T08:21:25.221741Z",
     "shell.execute_reply.started": "2022-03-08T08:21:25.177419Z"
    }
   },
   "outputs": [],
   "source": [
    "# print shape of fake dataset with rows and columns and information \n",
    "print (\"The shape of the  data is (row, column):\"+ str(fake_news.shape))\n",
    "print (fake_news.info())\n",
    "print(\"\\n --------------------------------------- \\n\")\n",
    "\n",
    "# print shape of true dataset with rows and columns and information\n",
    "print (\"The shape of the  data is (row, column):\"+ str(true_news.shape))\n",
    "print (true_news.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:25.223886Z",
     "iopub.status.busy": "2022-03-08T08:21:25.223663Z",
     "iopub.status.idle": "2022-03-08T08:21:25.229205Z",
     "shell.execute_reply": "2022-03-08T08:21:25.228561Z",
     "shell.execute_reply.started": "2022-03-08T08:21:25.223859Z"
    }
   },
   "outputs": [],
   "source": [
    "#Target variable for fake news\n",
    "fake_news['output']=0\n",
    "\n",
    "#Target variable for true news\n",
    "true_news['output']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:25.575581Z",
     "iopub.status.busy": "2022-03-08T08:21:25.575074Z",
     "iopub.status.idle": "2022-03-08T08:21:25.737207Z",
     "shell.execute_reply": "2022-03-08T08:21:25.736272Z",
     "shell.execute_reply.started": "2022-03-08T08:21:25.575549Z"
    }
   },
   "outputs": [],
   "source": [
    "#Concatenating and dropping for fake news\n",
    "fake_news['news']=fake_news['title']+fake_news['text']\n",
    "fake_news=fake_news.drop(['title', 'text'], axis=1)\n",
    "\n",
    "#Concatenating and dropping for true news\n",
    "true_news['news']=true_news['title']+true_news['text']\n",
    "true_news=true_news.drop(['title', 'text'], axis=1)\n",
    "\n",
    "#Rearranging the columns\n",
    "fake_news = fake_news[['subject', 'date', 'news','output']]\n",
    "true_news = true_news[['subject', 'date', 'news','output']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:26.10804Z",
     "iopub.status.busy": "2022-03-08T08:21:26.107775Z",
     "iopub.status.idle": "2022-03-08T08:21:26.173041Z",
     "shell.execute_reply": "2022-03-08T08:21:26.172044Z",
     "shell.execute_reply.started": "2022-03-08T08:21:26.108014Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing links and the headline from the date column\n",
    "fake_news=fake_news[~fake_news.date.str.contains(\"http\")]\n",
    "fake_news=fake_news[~fake_news.date.str.contains(\"HOST\")]\n",
    "\n",
    "'''You can also execute the below code to get the result \n",
    "which allows only string which has the months and rest are filtered'''\n",
    "fake_news=fake_news[fake_news.date.str.contains(\"Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:26.753836Z",
     "iopub.status.busy": "2022-03-08T08:21:26.753223Z",
     "iopub.status.idle": "2022-03-08T08:21:27.069143Z",
     "shell.execute_reply": "2022-03-08T08:21:27.068233Z",
     "shell.execute_reply.started": "2022-03-08T08:21:26.753791Z"
    }
   },
   "outputs": [],
   "source": [
    "#Converting the date to datetime format\n",
    "fake_news['date'] = pd.to_datetime(fake_news['date'])\n",
    "true_news['date'] = pd.to_datetime(true_news['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:27.320735Z",
     "iopub.status.busy": "2022-03-08T08:21:27.320424Z",
     "iopub.status.idle": "2022-03-08T08:21:27.347333Z",
     "shell.execute_reply": "2022-03-08T08:21:27.34667Z",
     "shell.execute_reply.started": "2022-03-08T08:21:27.320705Z"
    }
   },
   "outputs": [],
   "source": [
    "frames = [fake_news, true_news]\n",
    "news_dataset = pd.concat(frames)\n",
    "news_dataset.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:27.928172Z",
     "iopub.status.busy": "2022-03-08T08:21:27.927776Z",
     "iopub.status.idle": "2022-03-08T08:21:27.938684Z",
     "shell.execute_reply": "2022-03-08T08:21:27.937732Z",
     "shell.execute_reply.started": "2022-03-08T08:21:27.928144Z"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a copy \n",
    "clean_news=news_dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:28.6406Z",
     "iopub.status.busy": "2022-03-08T08:21:28.640048Z",
     "iopub.status.idle": "2022-03-08T08:21:28.644025Z",
     "shell.execute_reply": "2022-03-08T08:21:28.643138Z",
     "shell.execute_reply.started": "2022-03-08T08:21:28.640563Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:29.528696Z",
     "iopub.status.busy": "2022-03-08T08:21:29.528251Z",
     "iopub.status.idle": "2022-03-08T08:21:29.535437Z",
     "shell.execute_reply": "2022-03-08T08:21:29.534504Z",
     "shell.execute_reply.started": "2022-03-08T08:21:29.528649Z"
    }
   },
   "outputs": [],
   "source": [
    "def review_cleaning(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:21:30.119596Z",
     "iopub.status.busy": "2022-03-08T08:21:30.119312Z",
     "iopub.status.idle": "2022-03-08T08:22:08.262845Z",
     "shell.execute_reply": "2022-03-08T08:22:08.262017Z",
     "shell.execute_reply.started": "2022-03-08T08:21:30.119567Z"
    }
   },
   "outputs": [],
   "source": [
    "clean_news['news']=clean_news['news'].apply(lambda x:review_cleaning(x))\n",
    "clean_news.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:22:08.264658Z",
     "iopub.status.busy": "2022-03-08T08:22:08.264381Z",
     "iopub.status.idle": "2022-03-08T08:22:08.795124Z",
     "shell.execute_reply": "2022-03-08T08:22:08.794238Z",
     "shell.execute_reply.started": "2022-03-08T08:22:08.26463Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:22:08.79654Z",
     "iopub.status.busy": "2022-03-08T08:22:08.796282Z",
     "iopub.status.idle": "2022-03-08T08:22:08.986375Z",
     "shell.execute_reply": "2022-03-08T08:22:08.985732Z",
     "shell.execute_reply.started": "2022-03-08T08:22:08.796512Z"
    }
   },
   "outputs": [],
   "source": [
    "#Exploratory Data Analysis on the Election News at US\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:22:08.988345Z",
     "iopub.status.busy": "2022-03-08T08:22:08.987793Z",
     "iopub.status.idle": "2022-03-08T08:22:09.297664Z",
     "shell.execute_reply": "2022-03-08T08:22:09.297016Z",
     "shell.execute_reply.started": "2022-03-08T08:22:08.988315Z"
    }
   },
   "outputs": [],
   "source": [
    "#Plotting the frequency plot\n",
    "ax = sns.countplot(x=\"subject\", data=clean_news,\n",
    "                   facecolor=(0, 0, 0, 0),\n",
    "                   linewidth=7,\n",
    "                   edgecolor=sns.color_palette(\"dark\", 9))\n",
    "\n",
    "#Setting labels and font size\n",
    "ax.set(xlabel='Type of news', ylabel='Number of news',title='Count of news type')\n",
    "ax.xaxis.get_label().set_fontsize(10)\n",
    "ax.yaxis.get_label().set_fontsize(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:22:09.299426Z",
     "iopub.status.busy": "2022-03-08T08:22:09.298679Z",
     "iopub.status.idle": "2022-03-08T08:22:09.486048Z",
     "shell.execute_reply": "2022-03-08T08:22:09.485187Z",
     "shell.execute_reply.started": "2022-03-08T08:22:09.299375Z"
    }
   },
   "outputs": [],
   "source": [
    "ax=sns.countplot(x=\"output\", data=clean_news)\n",
    "\n",
    "#Setting labels and font size\n",
    "ax.set(xlabel='Output', ylabel='Count of fake/true',title='Count of fake and true news')\n",
    "ax.xaxis.get_label().set_fontsize(15)\n",
    "ax.yaxis.get_label().set_fontsize(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights:\n",
    "\n",
    "We have a pretty much balanced data\n",
    "\n",
    "But the count of fake news is higher than the true news but not on a greater extent\n",
    "\n",
    "Deriving new features from the news Lets extract more features from the news feature such as\n",
    "\n",
    "Polarity: The measure which signifies the sentiment of th news\n",
    "\n",
    "Review length: Length of the news(number of letters and spaces)\n",
    "\n",
    "Word Count: Number of words in the news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:22:09.488656Z",
     "iopub.status.busy": "2022-03-08T08:22:09.487317Z",
     "iopub.status.idle": "2022-03-08T08:22:10.764774Z",
     "shell.execute_reply": "2022-03-08T08:22:10.763807Z",
     "shell.execute_reply.started": "2022-03-08T08:22:09.488606Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from matplotlib import rcParams\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "from plotly import tools\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=False, world_readable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:22:10.76658Z",
     "iopub.status.busy": "2022-03-08T08:22:10.766239Z",
     "iopub.status.idle": "2022-03-08T08:24:24.538301Z",
     "shell.execute_reply": "2022-03-08T08:24:24.537408Z",
     "shell.execute_reply.started": "2022-03-08T08:22:10.766538Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting the features from the news\n",
    "clean_news['polarity'] = clean_news['news'].map(lambda text: TextBlob(text).sentiment.polarity)\n",
    "clean_news['review_len'] = clean_news['news'].astype(str).apply(len)\n",
    "clean_news['word_count'] = clean_news['news'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:25:00.303688Z",
     "iopub.status.busy": "2022-03-08T08:25:00.303394Z",
     "iopub.status.idle": "2022-03-08T08:25:43.911419Z",
     "shell.execute_reply": "2022-03-08T08:25:43.910486Z",
     "shell.execute_reply.started": "2022-03-08T08:25:00.303659Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to get top n words\n",
    "def get_top_n_words(corpus, n=None):\n",
    "    vec = CountVectorizer().fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "#Calling function and return only top 20 words\n",
    "common_words = get_top_n_words(clean_news['news'], 20)\n",
    "\n",
    "#Printing the word and frequency\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "\n",
    "#Creating the dataframe of word and frequency\n",
    "df1 = pd.DataFrame(common_words, columns = ['news' , 'count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:25:43.913192Z",
     "iopub.status.busy": "2022-03-08T08:25:43.912946Z",
     "iopub.status.idle": "2022-03-08T08:27:44.116248Z",
     "shell.execute_reply": "2022-03-08T08:27:44.115063Z",
     "shell.execute_reply.started": "2022-03-08T08:25:43.913159Z"
    }
   },
   "outputs": [],
   "source": [
    "#Function to get top trigram words\n",
    "def get_top_n_trigram(corpus, n=None):\n",
    "    vec = CountVectorizer(ngram_range=(3, 3), stop_words='english').fit(corpus)\n",
    "    bag_of_words = vec.transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "#Calling function and return only top 20 words\n",
    "common_words = get_top_n_trigram(clean_news['news'], 20)\n",
    "\n",
    "#Printing word and their respective frequencies\n",
    "for word, freq in common_words:\n",
    "    print(word, freq)\n",
    "\n",
    "#Creating a dataframe with words and count\n",
    "df6 = pd.DataFrame(common_words, columns = ['news' , 'count'])\n",
    "\n",
    "#Grouping the words and plotting their frequencies\n",
    "df6.groupby('news').sum()['count'].sort_values(ascending=False).iplot(\n",
    "    kind='bar', yTitle='Count', linecolor='black', title='Top 20 trigrams in news')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:27:44.117907Z",
     "iopub.status.busy": "2022-03-08T08:27:44.117674Z",
     "iopub.status.idle": "2022-03-08T08:27:54.703696Z",
     "shell.execute_reply": "2022-03-08T08:27:54.702893Z",
     "shell.execute_reply.started": "2022-03-08T08:27:44.11788Z"
    }
   },
   "outputs": [],
   "source": [
    "text = fake_news[\"news\"]\n",
    "wordcloud = WordCloud(\n",
    "    width = 3000,\n",
    "    height = 2000,\n",
    "    background_color = 'black',\n",
    "    stopwords = STOPWORDS).generate(str(text))\n",
    "fig = plt.figure(\n",
    "    figsize = (40, 30),\n",
    "    facecolor = 'k',\n",
    "    edgecolor = 'k')\n",
    "plt.imshow(wordcloud, interpolation = 'bilinear')\n",
    "plt.axis('off')\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:27:54.70588Z",
     "iopub.status.busy": "2022-03-08T08:27:54.705452Z",
     "iopub.status.idle": "2022-03-08T08:27:54.724871Z",
     "shell.execute_reply": "2022-03-08T08:27:54.723725Z",
     "shell.execute_reply.started": "2022-03-08T08:27:54.705847Z"
    }
   },
   "outputs": [],
   "source": [
    "#Extracting ' news' for processing\n",
    "news_features=clean_news.copy()\n",
    "news_features=news_features[['news']].reset_index(drop=True)\n",
    "news_features.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:27:54.726558Z",
     "iopub.status.busy": "2022-03-08T08:27:54.726131Z",
     "iopub.status.idle": "2022-03-08T08:33:34.807392Z",
     "shell.execute_reply": "2022-03-08T08:33:34.806644Z",
     "shell.execute_reply.started": "2022-03-08T08:27:54.726527Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "#Performing stemming on the news dataframe\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#splitting and adding the stemmed words except stopwords\n",
    "corpus = []\n",
    "for i in range(0, len(news_features)):\n",
    "    news = re.sub('[^a-zA-Z]', ' ', news_features['news'][i])\n",
    "    news= news.lower()\n",
    "    news = news.split()\n",
    "    news = [ps.stem(word) for word in news if not word in stop_words]\n",
    "    news = ' '.join(news)\n",
    "    corpus.append(news)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:33:34.80993Z",
     "iopub.status.busy": "2022-03-08T08:33:34.809288Z",
     "iopub.status.idle": "2022-03-08T08:34:34.070239Z",
     "shell.execute_reply": "2022-03-08T08:34:34.069458Z",
     "shell.execute_reply.started": "2022-03-08T08:33:34.809885Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000,ngram_range=(2,2))\n",
    "# TF-IDF feature matrix\n",
    "X= tfidf_vectorizer.fit_transform(news_features['news'])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:34:34.0715Z",
     "iopub.status.busy": "2022-03-08T08:34:34.07127Z",
     "iopub.status.idle": "2022-03-08T08:34:34.075906Z",
     "shell.execute_reply": "2022-03-08T08:34:34.075045Z",
     "shell.execute_reply.started": "2022-03-08T08:34:34.071458Z"
    }
   },
   "outputs": [],
   "source": [
    "#Getting the target variable\n",
    "y=clean_news['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:34:34.077167Z",
     "iopub.status.busy": "2022-03-08T08:34:34.07693Z",
     "iopub.status.idle": "2022-03-08T08:34:34.125668Z",
     "shell.execute_reply": "2022-03-08T08:34:34.124823Z",
     "shell.execute_reply.started": "2022-03-08T08:34:34.077143Z"
    }
   },
   "outputs": [],
   "source": [
    "## Divide the dataset into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:36:52.242292Z",
     "iopub.status.busy": "2022-03-08T08:36:52.241667Z",
     "iopub.status.idle": "2022-03-08T08:36:58.045826Z",
     "shell.execute_reply": "2022-03-08T08:36:58.044891Z",
     "shell.execute_reply.started": "2022-03-08T08:36:52.242242Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import re \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:37:34.465345Z",
     "iopub.status.busy": "2022-03-08T08:37:34.464292Z",
     "iopub.status.idle": "2022-03-08T08:37:35.672026Z",
     "shell.execute_reply": "2022-03-08T08:37:35.671231Z",
     "shell.execute_reply.started": "2022-03-08T08:37:34.465291Z"
    }
   },
   "outputs": [],
   "source": [
    "#Building the RNN.\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(max_vocab, 128),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:42:51.736894Z",
     "iopub.status.busy": "2022-03-08T08:42:51.736334Z",
     "iopub.status.idle": "2022-03-08T08:42:51.785023Z",
     "shell.execute_reply": "2022-03-08T08:42:51.783668Z",
     "shell.execute_reply.started": "2022-03-08T08:42:51.736845Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=10,validation_split=0.1, batch_size=30, shuffle=True, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-03-08T08:38:19.786563Z",
     "iopub.status.busy": "2022-03-08T08:38:19.786103Z",
     "iopub.status.idle": "2022-03-08T08:38:19.826122Z",
     "shell.execute_reply": "2022-03-08T08:38:19.824953Z",
     "shell.execute_reply.started": "2022-03-08T08:38:19.786513Z"
    }
   },
   "outputs": [],
   "source": [
    "#Visualize our training over time\n",
    "\n",
    "history_dict = history.history\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "epochs = history.epoch\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss', size=20)\n",
    "plt.xlabel('Epochs', size=20)\n",
    "plt.ylabel('Loss', size=20)\n",
    "plt.legend(prop={'size': 20})\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs, acc, 'g', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy', size=20)\n",
    "plt.xlabel('Epochs', size=20)\n",
    "plt.ylabel('Accuracy', size=20)\n",
    "plt.legend(prop={'size': 20})\n",
    "plt.ylim((0.5,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the testing set\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)\n",
    "\n",
    "binary_predictions = []\n",
    "\n",
    "for i in pred:\n",
    "    if i >= 0.5:\n",
    "        binary_predictions.append(1)\n",
    "    else:\n",
    "        binary_predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy on testing set:', accuracy_score(binary_predictions, y_test))\n",
    "print('Precision on testing set:', precision_score(binary_predictions, y_test))\n",
    "print('Recall on testing set:', recall_score(binary_predictions, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(binary_predictions, y_test, normalize='all')\n",
    "plt.figure(figsize=(16, 10))\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(matrix, annot=True, ax = ax)\n",
    "\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted Labels', size=20)\n",
    "ax.set_ylabel('True Labels', size=20)\n",
    "ax.set_title('Confusion Matrix', size=20) \n",
    "ax.xaxis.set_ticklabels([0,1], size=15)\n",
    "ax.yaxis.set_ticklabels([0,1], size=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
